{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition and training of the SpotNet computational graph\n",
    "\n",
    "In this code section, we define a network that approximately implements a number of iterations of the accelerated proximal gradient algorithm for detecting spots in FluoroSpot. From there on, we will train the network to get closer to the optimal than the actual number of iterations of the algorithm.  \n",
    "\n",
    "<a id=\"network_figure\"></a>\n",
    "\n",
    "|[![network picture][network]](pics/network.pdf)|\n",
    "| --:-- |\n",
    "|<center>Fig 1: *Computation graph of SpotNet, extracted from the accelerated proximal gradient algorithm applied to regularized least-squares recovery of a FluoroSpot image using our mathematical model (see the paper and [`data_simulation.ipynb`](./data_simulation.ipynb) and \\[[1][1],[2][2]\\] for details). *</center>|\n",
    "\n",
    "# References\n",
    "\n",
    "[1]: https://arxiv.org/abs/1710.01604\n",
    "[2]: https://arxiv.org/abs/1710.01622\n",
    "\n",
    "[\\[1\\]][1]: Pol del Aguila Pla and Joakim Jaldén, \"Cell Detection by Functional Inverse Diffusion and Group Sparsity − Part I: Modeling and Inverse Problems\", _IEEE Transactions on Signal Processing_, vol. 66, no. 20, pp. 5407--5421, 2018  \n",
    "[\\[2\\]][2]: Pol del Aguila Pla and Joakim Jaldén, \"Cell Detection by Functional Inverse Diffusion and Group Sparsity − Part II: Proximal Optimization and Performance Evaluation\", _IEEE Transactions on Signal Processing_, vol. 66, no. 20, pp. 5422--5437, 2018  \n",
    "\n",
    "# Index\n",
    "\n",
    "1. Definition of computational graph of SpotNet\n",
    "    1. [Importing libraries](#libs) to build and initialize the network\n",
    "    2. [Library of non-linear functions](#phis) $\\varphi_\\lambda(\\cdot)$\n",
    "    3. Library for initial [kernel generation](#kers)\n",
    "    4. Generator of [single hidden layers](#hidden) of SpotNet\n",
    "    5. Definition of the [full SpotNet computational graph](#spotnet)\n",
    "    6. Definition of the [training strategy](#training_strategy) for SpotNet\n",
    "2. Training of SpotNet\n",
    "    1. [Loading of the training data-base](#data) and setting of parameters \n",
    "    2. Construction of the [computational graph](#session)\n",
    "    3. Running the [training](#training) and storing its results\n",
    "    \n",
    "\n",
    "[network]: pics/network.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition of computational graph of SpotNet\n",
    "\n",
    "<a id=\"libs\"></a>\n",
    "## Importing libraries to build and initialize the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow for differentiable programming\n",
    "import tensorflow as tf\n",
    "# Numpy for array management\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"phis\"></a>\n",
    "## Library of non-linear functions $\\varphi_\\lambda(\\cdot)$\n",
    "\n",
    "These are linked to specific regularizers through proximal operators, in the sense that $\\varphi_\\lambda(x) = \\mbox{prox}_{\\lambda\\mathcal{R}}(x)$, where $\\mathcal{R}(x)$ is a regularizer that promotes certain characteristics of the three-dimensional array $x\\in\\mathbb{R}^{M\\times N \\times K}$, while \n",
    "$$\n",
    "    \\mbox{prox}_{\\lambda\\mathcal{R}}(x) = \\arg \\min_y \\left\\lbrace \\mathcal{R}(x) + \\frac{1}{2\\lambda}\\left\\|y-x\\right\\| \\right\\rbrace.\\,\\,(1)\n",
    "$$\n",
    "\n",
    "Here, we include the cases \n",
    "$$\n",
    "\\mathcal{R}(x)= \\mathcal{R}_\\mathrm{s}(x) = \\sum_{k=1}^{K} \\left\\| x_k \\right\\|_1 = \\sum_{m,n,k=1}^{M,N,K} \\left|x_{m,n,k}\\right| \\, \\,\\,(2)\n",
    "$$\n",
    "and $\\mathcal{R}(x)= \\mathcal{R}_\\mathrm{s}(x) + \\delta_{\\mathbb{R}^{M,N,K}_+}(x)\\, \\,\\,(3)$ to promote sparsity and non-negative sparsity, respectively, but also\n",
    "$$\n",
    "\\mathcal{R}(x)= \\mathcal{R}_\\mathrm{gs}(x) = \\sum_{m,n=1}^{M,N} \\sqrt{ \\sum_{k=1}^K x_k^2[i,j] }\\,, \\,\\,(4)\n",
    "$$\n",
    "and\n",
    "$\\mathcal{R}(x)= \\mathcal{R}_\\mathrm{gs}(x) + \\delta_{\\mathbb{R}^{M,N,K}_+}(x)\\, \\,\\,(5)$ to promote group-sparsity and non-negative group-sparsity with groups corresponding to each specific location in the image (see \\[[1][1],[2][2]\\] to understand why this would be a good idea for the problem addressed in the paper). Here, $\\delta_{\\mathbb{R}^{M,N,K}_+}(x)$ is the non-negativity\n",
    "$(\\infty,0)$-indicator function of the non-negative half-space, i.e., \n",
    "$$\n",
    "    \\delta_{\\mathbb{R}^{M,N,K}_+}(x) = \\begin{cases} \\infty & \\mbox{ if }x_{m,n,k}\\geq 0, \\forall m,n,k \\\\\n",
    "    0 & \\mbox{ otherwise,} \\end{cases}\n",
    "$$\n",
    "which is a common construct to include constraints in the regularization term in non-smooth convex optimization.\n",
    "\n",
    "[1]: https://arxiv.org/abs/1710.01604\n",
    "[2]: https://arxiv.org/abs/1710.01622"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prox of Sparsity (l1 norm, (2))\n",
    "def soft_threshold( x, lam = 1.0 ):\n",
    "    b = tf.Variable( lam )\n",
    "    return (tf.nn.relu( x + b ) + tf.nn.relu( -x-b )) \n",
    "# Prox of Group sparsity (l2 norm along groups summed for all groups, (4)) \n",
    "# NWHC format with the same location in different channels belonging to the same group\n",
    "def soft_group_threshold( x, lam = 1.0 ):\n",
    "    b = tf.Variable(  lam )\n",
    "    norm = tf.reduce_sum( x**2, 3 )\n",
    "    return tf.expand_dims( tf.maximum( 1 - b / norm, 0 ) , axis = 3 ) * x\n",
    "# Prox of Non-negative Sparsity (l1 norm + non-negative infinity-0 indicator, (3))\n",
    "def s_nonneg( x, lam = 1.0 ):\n",
    "    b = tf.Variable( lam )\n",
    "    return tf.nn.relu( x - b )\n",
    "# Prox of Non-negative Group Sparsity \n",
    "# (l2 norm along groups summed for all groups + non-negative infinity-0 indicator, (5))\n",
    "def gs_nonneg( x ):\n",
    "    return soft_group_threshold( tf.maximum( x, 0 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"kers\"></a>\n",
    "## Initial for initial kernel generation\n",
    "\n",
    "Kernel generation functions. Conceptually, one would initially start by using the same kernels than the algorithm would. However, since the ultimate objective is to reduce computational cost, we generate random kernels of a given size, much smaller than that used by the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate non-negative random kernels of a given size. \n",
    "# The truncated normal with standard deviation 0.01 was selected for convenience.\n",
    "def generate_random_kernels( kernel_size, nrof_kernels ):\n",
    "        \n",
    "    kernels = tf.Variable( tf.truncated_normal( [kernel_size,\n",
    "                                                 kernel_size,\n",
    "                                                 nrof_kernels,\n",
    "                                                 1], stddev = 0.01 ) )\n",
    "\n",
    "    return kernels\n",
    "\n",
    "# As an alternative: generate kernels given by the accelerated proximal gradient for the mathematical model\n",
    "# for FluoroSpot (very large)\n",
    "\n",
    "# Import kernel generation from corresponding python module in our local folders\n",
    "import ker\n",
    "# Set sigma limits to match those obtained in data_generation.ipynb\n",
    "sigma_lims = np.array(\n",
    "                     [ 0.        ,  2.03803742,  4.07607485,  6.44484021,  8.64666049,\n",
    "                       10.78428037, 12.88968043, 14.97645529, 17.17280857, 19.33452064,\n",
    "                       21.47205663, 23.59198881, 25.77936086, 27.94416127, 30.09126194,\n",
    "                       32.22420107, 34.34561714, 36.5144422 , 38.66904129, 40.8116676 ,\n",
    "                       42.94411325, 45.1138815 , 47.27192547, 49.41978111, 51.55872171,\n",
    "                       53.68981279, 55.8511504 , 58.00356193, 60.14800566, 62.28530458,\n",
    "                       64.44840214 ] )\n",
    "# Produce function to generate kernels according to the FluoroSpot model\n",
    "generate_diffusion_kernels = lambda: ker.obtain_discrete_kernels( sigma_lims )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"hidden\"></a>\n",
    "## Definition of a single hidden layers of SpotNet\n",
    "\n",
    "To be compared with a generic iteration / hidden layer in [Fig. 1](#network_figure). Basically defining an iteration of the accelerated proximal gradient algorithm for the problem at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hidden_layer( x_prev, z_prev, source, kernels, non_linearity = soft_threshold ):\n",
    "    \n",
    "    # Create variable for tunable kernels\n",
    "    h = tf.Variable( kernels )\n",
    "    # Depthwise convolution\n",
    "    conv = tf.nn.depthwise_conv2d( input = z_prev,\n",
    "                                   filter = h,\n",
    "                                   strides = [1, 1, 1, 1],\n",
    "                                   padding = 'SAME' )\n",
    "    # Sum of all convolutions and difference to observed image\n",
    "    u = tf.reduce_sum( conv, 3 ) - source\n",
    "    u = tf.expand_dims( u, 3 )\n",
    "    # Defining the matched filters\n",
    "    h_m = tf.transpose( tf.reverse( tf.reverse( h, [0] ), [1] ), [0, 1, 3, 2] )\n",
    "    # Convolve results of sum by each of the different matched filters\n",
    "    conv_m = tf.nn.conv2d( input = u,\n",
    "                           filter = h_m,\n",
    "                           strides = [1, 1, 1, 1],\n",
    "                           padding = 'SAME' )\n",
    "    # Pass through non-linearity\n",
    "    x_current = non_linearity( z_prev - conv_m )\n",
    "    # Perform acceleration step (skip connections)\n",
    "    alpha = tf.Variable( tf.constant( 0.5 ) )\n",
    "    z_current = x_current + alpha * (x_current - x_prev)\n",
    "        \n",
    "    return (x_current, z_current, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"spotnet\"></a>\n",
    "## Definition of the full SpotNet computational graph\n",
    "To be compared with the overall structure in [Fig. 1](#network_figure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spot_finding_net( nrof_images,\n",
    "                      image_height, \n",
    "                      image_width, \n",
    "                      kernels,\n",
    "                      nrof_hidden_layers,\n",
    "                      non_linearity = soft_threshold ):\n",
    "    \n",
    "    # Seed for random initializations\n",
    "    tf.set_random_seed(8888)\n",
    "    \n",
    "    # Placeholder for final FluoroSpot images\n",
    "    source = tf.placeholder( tf.float32, [ nrof_images, image_height, image_width ] )\n",
    "    \n",
    "    # Create the input half-layer (equivalent to first iteration with initialization of 0)\n",
    "    # Convolve by each of the matched filters and pass through non-linearity\n",
    "    h_m = tf.transpose( tf.reverse( tf.reverse( kernels, [0] ), [1] ), [0, 1, 3, 2] )\n",
    "    x = [ non_linearity( tf.nn.conv2d( input = tf.expand_dims( source, 3 ),\n",
    "                                       filter = h_m,\n",
    "                                       strides = [1, 1, 1, 1],\n",
    "                                       padding = 'SAME' ) ) ]\n",
    "    # Acceleration step (skip connection)\n",
    "    alpha = tf.Variable( tf.constant( 0.5 ) )\n",
    "    z = [ (1 + alpha) * x[-1] ]\n",
    "    h = []\n",
    "    \n",
    "    # Create hidden layers as a feedforward convolutional graph. Append each hidden \n",
    "    # layer to a list and connect next layer to the last element of this list.\n",
    "    for i in range( nrof_hidden_layers ):\n",
    "        x_current, z_current, h_current = hidden_layer( x[-1], z[-1], source, kernels, non_linearity )\n",
    "        \n",
    "        x.append(x_current)\n",
    "        z.append(z_current)\n",
    "        h.append(h_current)\n",
    "        \n",
    "    # The output is simply the last x\n",
    "    output = x[-1]\n",
    "    \n",
    "    # Placeholder for the target x\n",
    "    target = tf.placeholder( tf.float32, [ nrof_images, image_height, image_width, nrof_kernels ] )\n",
    "    \n",
    "    # Mean squared error for the prediction of x\n",
    "    loss = tf.reduce_mean( ( output - target ) ** 2 )\n",
    "    \n",
    "    # Return input and target placeholders, loss to optimize, and output to obtain\n",
    "    return (source, loss, target, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"training_strategy\"></a>\n",
    "## Definition of the training strategy for SpotNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and return the optimizer\n",
    "def network_training( loss, learning_rate ):\n",
    "    return tf.train.AdamOptimizer( learning_rate ).minimize( loss )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"training_sec\"></a>\n",
    "# Training of SpotNet\n",
    "\n",
    "<a id = \"data\"></a>\n",
    "## Loading of the training data-base and setting of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network parameters\n",
    "nrof_hidden_layers = 3\n",
    "\n",
    "# Learning process parameters\n",
    "learning_rate = 1e-3\n",
    "batch_size = 1\n",
    "nrof_train_steps = 400000\n",
    "nrof_cells = 1250\n",
    "\n",
    "# Relevant directories\n",
    "results_dir = 'results/'\n",
    "data_dir = 'sim_data/'\n",
    "\n",
    "# Load dataset\n",
    "data = np.load( data_dir + 'result_' + str( nrof_cells ) + '_cells_10_images.npy' )[()]\n",
    "\n",
    "# Extract images and xs\n",
    "images = data['fluorospot']\n",
    "psdrs  = data['psdrs']\n",
    "\n",
    "# Extract shape parameters\n",
    "nrof_images, image_height, image_width = images.shape\n",
    "_, _, _, nrof_kernels = psdrs.shape\n",
    "\n",
    "# Split dataset for training and validation\n",
    "nrof_training_samples = int( 0.7 * nrof_images )\n",
    "train_images, train_psdrs = (images[: nrof_training_samples, ...], psdrs[: nrof_training_samples, ...])\n",
    "val_images, val_psdrs = (images[nrof_training_samples :, ...], psdrs[nrof_training_samples :, ...])\n",
    "\n",
    "print( 'Dataset: Num images: %d, Image height: %d, Image width: %d, Num cells: %d, Num kernels: %d'%( nrof_images, \n",
    "                                                                                                      image_height, \n",
    "                                                                                                      image_width,\n",
    "                                                                                                      nrof_cells,\n",
    "                                                                                                      nrof_kernels ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"session\"></a>\n",
    "## Construction of the computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get kernels to initialize the network\n",
    "kernels = generate_random_kernels(5, 30) \n",
    "\n",
    "# Build computational graph\n",
    "with tf.name_scope( 'SpotNet' ) as scope:\n",
    "    source, loss, target, output = spot_finding_net( batch_size,\n",
    "                                                     image_height, \n",
    "                                                     image_width, \n",
    "                                                     kernels,\n",
    "                                                     nrof_hidden_layers,\n",
    "                                                     soft_threshold )\n",
    "\n",
    "# Build training computational graph\n",
    "with tf.name_scope( 'Training' ) as scope:\n",
    "    train_step = network_training( loss, learning_rate )\n",
    "\n",
    "# Create TensorFlow session to run the computational graph\n",
    "nrof_gpus = 1 \n",
    "config = tf.ConfigProto( device_count = {'GPU': nrof_gpus} )\n",
    "sess = tf.Session( config = config )\n",
    "sess.run( tf.global_variables_initializer( ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"training\"></a>\n",
    "## Running training and storing its results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time library to time training\n",
    "import time\n",
    "\n",
    "# Inform user\n",
    "print( 'Training the network' )\n",
    "\n",
    "# Space to store loss values\n",
    "train_loss_record = np.empty( (0, ) )\n",
    "val_loss_record  = np.empty( (0, ) )\n",
    "iterations_record = np.empty( (0, ) )\n",
    "\n",
    "# Indices that will be picked at random at each iteration\n",
    "indices = np.arange( train_images.shape[0] )\n",
    "\n",
    "# Seed for reproducibility\n",
    "np.random.seed( 8888 )\n",
    "\n",
    "# Train the network\n",
    "# Start timing\n",
    "start = time.time()\n",
    "for training_iteration in range( nrof_train_steps + 1 ):\n",
    "    # Shuffle indices    \n",
    "    np.random.shuffle( indices )\n",
    "    # Extract current batch\n",
    "    batch_indices = np.take( indices, np.arange( batch_size ), mode = 'wrap' )\n",
    "    batch_input = train_images[ batch_indices, ... ]\n",
    "    batch_target = train_psdrs[ batch_indices, ... ]\n",
    "    # Run a training step\n",
    "    _, train_loss = sess.run( [ train_step, loss ], feed_dict = { source: batch_input, \n",
    "                                                                  target: batch_target } )\n",
    "    # Every 100th of total iterations, record progress in terms of validation loss    \n",
    "    if training_iteration % (nrof_train_steps / 100) == 0:\n",
    "        # Sum validation losses\n",
    "        val_loss = 0\n",
    "        for val_image_index in range( val_images.shape[0] ):\n",
    "            val_loss += sess.run( loss, feed_dict = { source: np.expand_dims( val_images[ val_image_index, ... ], axis = 0 ), \n",
    "                                                      target: np.expand_dims( val_psdrs[  val_image_index, ... ], axis = 0 ) } )\n",
    "        # Divide by number of validation images\n",
    "        val_loss = val_loss / val_images.shape[0]\n",
    "        # Store losses\n",
    "        val_loss_record = np.append( val_loss_record, val_loss )\n",
    "        train_loss_record = np.append( train_loss_record, train_loss )\n",
    "        iterations_record = np.append( iterations_record, training_iteration )\n",
    "        # Inform the user and store the model if it is the best one yet\n",
    "        if (val_loss == val_loss_record.min() and training_iteration > 10):\n",
    "            print( 'Train step %d, Batch loss: %0.4f, Test loss: %0.4f, Elapsed: %ds. Best in validation yet! Storing.'%( \n",
    "                                                                                    training_iteration, \n",
    "                                                                                    train_loss, \n",
    "                                                                                    val_loss, \n",
    "                                                                                    time.time() - start ) ) \n",
    "            tf.saved_model.simple_save( sess,\n",
    "                results_dir + 'trained_spotnet_' + str( training_iteration ) + '_train-steps_5_kersize/',\n",
    "                inputs = {'image': source},\n",
    "                outputs = {'psdr': output} )\n",
    "        else:\n",
    "            print( 'Train step %d, Batch loss: %0.4f, Test loss: %0.4f, Elapsed: %ds.'%( \n",
    "                                                                                    training_iteration, \n",
    "                                                                                    train_loss, \n",
    "                                                                                    val_loss, \n",
    "                                                                                    time.time() - start ) )\n",
    "\n",
    "# Store loss values\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
