# SpotNet &mdash; Learned Iterations for Cell Detection in Image-based Immunoassays
### Pol del Aguila Pla [\[2\]][2], Vidit Saxena [\[3\]][3], and Joakim Jaldén [\[4\]][4]

This GitHub repository contains the code and explanations that complement the paper of the same name (which can be downloaded from [\[1\]][1]), submitted to the 2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019) [\[5\]][5]. The code provided here is **still not ready** for functioning when **being run directly and naively**, but it will get to that level in the coming weeks. There are two main ways of exploring the Jupyter notebooks we provide:  
1. Running them on your computer / computational server to fully or partially replicate our results, or    
2. visualizing them through [nbviewer.jupyter.org](https://nbviewer.jupyter.org/github/poldap/SpotNet/tree/master/).

[\[1\]][1]: Pre-print of the article in arXiv.org, arXiv:1810.06132 \[eess.IV\]  
[\[2\]][2]: Pol del Aguila Pla's research website  
[\[3\]][3]: Vidit Saxena's research profile at KTH  
[\[4\]][4]: Joakim Jaldén's research profile at KTH  
[\[5\]][5]: ISBI 2019 website

[1]: https://arxiv.org/abs/1810.06132
[2]: https://poldap.github.io  
[3]: https://kth.se/profile/vidits   
[4]: https://kth.se/profile/jalden 
[5]: https://biomedicalimaging.org/2019/

## Prerequisites

### Hardware 

In order to run our code successuflly and in a moderate time, you will need access to a powerful computer, preferably equipped with a GPU. For reference, we report the timings for the most demanding computations, and all our experiments were run on a computer equipped with a [NVIDIA Tesla P100](https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/tesla-p100/pdf/nvidia-tesla-p100-datasheet.pdf) GPU, an [Intel(R) Xeon(R) E5-1650 v3](https://ark.intel.com/products/82765/Intel-Xeon-Processor-E5-1650-v3-15M-Cache-3-50-GHz-) CPU and 62 GB of RAM. If you do not have this option, we recommend skipping the training of the models and running only the notebooks that relate to data generation and evaluation, relying on the trained models that we provide (_not available yet_). Of course, you can still investigate how these were generated by using nbviewer to explore [spot_net.ipynb](https://nbviewer.jupyter.org/github/poldap/SpotNet/blob/master/spot_net.ipynb) and [conv_net.ipynb](https://nbviewer.jupyter.org/github/poldap/SpotNet/blob/master/conv_net.ipynb).

1. Python 3,
2. Jupyter  
3. Tensorflow  
  
Access to a GPU is expected to greatly speed up the data generation and evaluations.  

## Executing the code

The code is organized as Jupyter notebooks running IPython. If you are unfamilir with Jupyter notebooks, you can refer to any of the several existing tutorials, for example this one: [Getting Started With Jupyter Notebook for Python](https://medium.com/codingthesmartway-com-blog/getting-started-with-jupyter-notebook-for-python-4e7082bd5d46).

## Data Generation

The generation of synthetic Fluorospot images is provided by `data_simulation.ipynb`. After you have started the Jupyter notebook server from your cloned Spotnet directory, you should be able to open and run `data_simulation.ipynb` in your browser.  
  
If you need to understand the theory behind image generation, follow the explanations for each cell and run them sequentially. When all the cells have been run, the images will be generated and stored in a newly created `sim_data` directory.  
  
Alternatively, You can generate images directly with the default parameters by running `Kernel -> Restart and Run All`

**Note**: The generation of images with default parameters is expected to take several minutes, and may even take up to a few hours in non-GPU systems.

## SpotNet Evaluation

Once the data has been generated, it will be stored in the `sim_data` directory. Run the `spot_net.ipynb` notebook by running `Kernel -> Restart and Run All`.  

## ConvNet Evaluation
  
Once the data has been generated, it will be stored in the `sim_data` directory. Run the `conv_net.ipynb` notebook by running `Kernel -> Restart and Run All`.
  
