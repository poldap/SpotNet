# SpotNet &mdash; Learned Iterations for Cell Detection in Image-based Immunoassays
### Pol del Aguila Pla [\[2\]][2], Vidit Saxena [\[3\]][3], and Joakim Jaldén [\[4\]][4]

This GitHub repository contains the code and explanations that complement the paper of the same name (which can be downloaded from [\[1\]][1]), submitted to the 2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019) [\[5\]][5]. The code provided here is **still not ready** for functioning when **being run directly and naively**, but it will get to that level in the coming weeks. There are two main ways of exploring the Jupyter notebooks we provide:  
1. Running them on your computer / computational server to fully or partially replicate our results, or    
2. visualizing them through [`nbviewer.jupyter.org`](https://nbviewer.jupyter.org/github/poldap/SpotNet/tree/master/).

[\[1\]][1]: Pre-print of the article in arXiv.org, arXiv:1810.06132 \[eess.IV\]  
[\[2\]][2]: Pol del Aguila Pla's research website  
[\[3\]][3]: Vidit Saxena's research profile at KTH  
[\[4\]][4]: Joakim Jaldén's research profile at KTH  
[\[5\]][5]: ISBI 2019 website

[1]: https://arxiv.org/abs/1810.06132
[2]: https://poldap.github.io  
[3]: https://kth.se/profile/vidits   
[4]: https://kth.se/profile/jalden 
[5]: https://biomedicalimaging.org/2019/

## Prerequisites

### Hardware 

In order to run our code successfully and in a moderate time, you will need access to a powerful computer, preferably equipped with a GPU. For reference, we report the timings for the most demanding computations, and all our experiments were run on a computer equipped with an [NVIDIA Tesla P100](https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/tesla-p100/pdf/nvidia-tesla-p100-datasheet.pdf) GPU, an [Intel Xeon E5-1650 v3](https://ark.intel.com/products/82765/Intel-Xeon-Processor-E5-1650-v3-15M-Cache-3-50-GHz-) CPU, and 62 GB of RAM. If you do not have this option, we recommend skipping the training of the models and running only the notebooks that relate to data generation and evaluation. That will use the trained models that we provide instead (_not available yet_), and still verify our results. Of course, you can investigate how these trained models were generated by using `nbviewer` to explore [spot_net.ipynb](https://nbviewer.jupyter.org/github/poldap/SpotNet/blob/master/spot_net.ipynb) and [conv_net.ipynb](https://nbviewer.jupyter.org/github/poldap/SpotNet/blob/master/conv_net.ipynb).

### Software

To be able to run our code in your own computer or computational server, you will need to ensure the following software is available:
1. [Python 3](https://www.python.org/) (for reference, we used `python 3.6.5`), along with the scientific computing packages [`numpy`](http://www.numpy.org/), [`scipy`](https://www.scipy.org/), [`scikit-image`](https://scikit-image.org/), and [`matplotlib`](https://matplotlib.org/).
2. [Jupyter](https://jupyter.org/) (for reference, we used `jupyter 4.4.0`),
3. and [TensorFlow](https://www.tensorflow.org/) (for reference, we used `tensorflow 1.8.0` compiled for use in the GPU with `cudnn 7.1` and `nccl 2.1.15`). 

## Executing the code

Most of our code is organized as Jupyter notebooks containing Python code. If you are unfamiliar with Jupyter notebooks, you can refer to any of the many existing tutorials, e.g.: [Getting Started With Jupyter Notebook for Python](https://medium.com/codingthesmartway-com-blog/getting-started-with-jupyter-notebook-for-python-4e7082bd5d46).

### Data generation

The generation of synthetic Fluorospot images is provided by [`data_simulation.ipynb`](https://nbviewer.jupyter.org/github/poldap/SpotNet/blob/master/data_simulation.ipynb). After you have started the Jupyter notebook server from your cloned SpotNet directory, you should be able to open and run `data_simulation.ipynb` in your browser.  
  
To understand the theory behind image generation, follow the explanations for each cell and run them sequentially. When all the cells have been run, the images will be generated and stored in the `sim_data` directory. Alternatively, you can generate the images directly with the default parameters by using the menu and selecting `Kernel -> Restart and Run All`.

**Note**: The generation of images with default parameters is expected to take several minutes, and may even take up to a few hours in non-GPU systems.

### SpotNet training (optional)

Once the data has been generated, it will be stored in the `sim_data` directory. Run the `spot_net.ipynb` notebook by running `Kernel -> Restart and Run All`.  

### ConvNet training (optional)
  
Once the data has been generated, it will be stored in the `sim_data` directory. Run the `conv_net.ipynb` notebook by running `Kernel -> Restart and Run All`.

### Evaluation of the trained models





  
